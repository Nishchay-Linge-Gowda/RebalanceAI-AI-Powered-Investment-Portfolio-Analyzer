{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance plotly openai pandas numpy requests beautifulsoup4 lxml streamlit pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "YAs29d01PPnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rebalance_backend.py\n",
        "import os, re, time, requests, pandas as pd, numpy as np, yfinance as yf\n",
        "import plotly.express as px\n",
        "from bs4 import BeautifulSoup\n",
        "from io import StringIO\n",
        "\n",
        "\n",
        "# 1. Fetch S&P 500 tickers\n",
        "\n",
        "def get_sp500_tickers():\n",
        "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    html = requests.get(url, headers=headers).text\n",
        "    df = pd.read_html(StringIO(html))[0]\n",
        "    tickers = df[\"Symbol\"].str.replace('.', '-', regex=False).tolist()\n",
        "    print(f\"Loaded {len(tickers)} tickers.\")\n",
        "    return tickers\n",
        "\n",
        "\n",
        "# 2. Download Yahoo Finance data + Sharpe ratio\n",
        "\n",
        "def get_stock_data(tickers, period=\"6mo\"):\n",
        "    data = {}\n",
        "    for t in tickers:\n",
        "        try:\n",
        "            df = yf.download(t, period=period, progress=False, auto_adjust=True)\n",
        "            if not df.empty:\n",
        "                df[\"Return\"] = df[\"Close\"].pct_change()\n",
        "                df[\"Volatility\"] = df[\"Return\"].rolling(20).std()\n",
        "                data[t] = df.dropna()\n",
        "        except Exception:\n",
        "            pass\n",
        "    print(f\"Downloaded data for {len(data)} tickers.\")\n",
        "    return data\n",
        "\n",
        "def compute_metrics(data):\n",
        "    rows = []\n",
        "    for t, df in data.items():\n",
        "        if \"Return\" in df.columns and \"Volatility\" in df.columns:\n",
        "            mean_ret = df[\"Return\"].mean()\n",
        "            vol = df[\"Volatility\"].mean()\n",
        "            sharpe = mean_ret / vol if vol else 0\n",
        "            rows.append({\"Ticker\": t, \"Sharpe\": round(sharpe, 3)})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# 3. Google News + GPT Sentiment\n",
        "\n",
        "def fetch_recent_headlines(ticker, n=5):\n",
        "    url = f\"https://news.google.com/rss/search?q={ticker}+stock\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    try:\n",
        "        r = requests.get(url, headers=headers, timeout=8)\n",
        "        soup = BeautifulSoup(r.content, \"xml\")\n",
        "        return [item.title.text for item in soup.find_all(\"item\")[:n]]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def analyze_sentiment(client, ticker, headlines):\n",
        "    if not headlines:\n",
        "        return 0.0\n",
        "    prompt = (\n",
        "        f\"You are a financial analyst. Rate the overall sentiment toward {ticker} \"\n",
        "        f\"from these headlines between -1 (very bearish) and +1 (very bullish). \"\n",
        "        \"Respond with only one number.\\n\\n\" + \"\\n\".join(f\"- {h}\" for h in headlines)\n",
        "    )\n",
        "    try:\n",
        "        r = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "        )\n",
        "        out = r.choices[0].message.content.strip()\n",
        "        m = re.search(r\"-?\\d+(\\.\\d+)?\", out)\n",
        "        return float(m.group()) if m else 0.0\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "def compute_sentiment_scores(client, tickers, top_n=50):\n",
        "    scores = []\n",
        "    for t in tickers[:top_n]:\n",
        "        headlines = fetch_recent_headlines(t)\n",
        "        val = analyze_sentiment(client, t, headlines)\n",
        "        scores.append({\"Ticker\": t, \"Sentiment\": round(val, 3)})\n",
        "        time.sleep(0.2)\n",
        "    for t in tickers[top_n:]:\n",
        "        scores.append({\"Ticker\": t, \"Sentiment\": 0.0})\n",
        "    print(f\"Generated sentiment for {top_n} tickers.\")\n",
        "    return pd.DataFrame(scores)\n",
        "\n",
        "\n",
        "# 4. Portfolio generation + visualization\n",
        "\n",
        "def generate_portfolio(tickers, client):\n",
        "    data = get_stock_data(tickers)\n",
        "    metrics_df = compute_metrics(data)\n",
        "    sentiment_df = compute_sentiment_scores(client, tickers, top_n=len(tickers))\n",
        "\n",
        "    df = pd.merge(metrics_df, sentiment_df, on=\"Ticker\", how=\"inner\").fillna(0)\n",
        "    df[\"Score\"] = 0.6 * df[\"Sharpe\"] + 0.4 * df[\"Sentiment\"]\n",
        "    df[\"Weight\"] = df[\"Score\"] / df[\"Score\"].sum()\n",
        "    df[\"Weight_abs\"] = df[\"Weight\"].abs()\n",
        "\n",
        "    # Pie chart â€“ Top 25\n",
        "    fig1 = px.pie(df.head(25), values=\"Weight_abs\", names=\"Ticker\",\n",
        "                  title=\"Portfolio Allocation (Top 25 Weights)\",\n",
        "                  color_discrete_sequence=px.colors.qualitative.Set3)\n",
        "    fig1.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\n",
        "\n",
        "    # Scatter â€“ Sharpe vs Sentiment\n",
        "    fig2 = px.scatter(df, x=\"Sharpe\", y=\"Sentiment\", size=\"Weight_abs\",\n",
        "                      color=\"Score\", hover_name=\"Ticker\",\n",
        "                      title=\"Sharpe vs Sentiment (S&P 500 Universe)\",\n",
        "                      color_continuous_scale=\"Viridis\")\n",
        "    fig2.update_layout(yaxis_title=\"Sentiment\", xaxis_title=\"Sharpe Ratio\")\n",
        "\n",
        "    return df.sort_values(by=\"Weight\", ascending=False), fig1, fig2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS8YZ6ubPafd",
        "outputId": "9bdb701d-4470-483e-ddda-ccc023a3fbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rebalance_backend.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "from rebalance_backend import get_sp500_tickers, generate_portfolio\n",
        "\n",
        "\n",
        "# APP CONFIG\n",
        "\n",
        "st.set_page_config(page_title=\"RebalanceAI Copilot\", layout=\"wide\")\n",
        "st.title(\"RebalanceAI â€” S&P 500 Portfolio Copilot\")\n",
        "\n",
        "# Sidebar Info\n",
        "st.sidebar.markdown(\"### Applied Generative AI Hackathon\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "**Group 4**\n",
        "- Nishchay Linge Gowda\n",
        "- Shivakumar Hassan Lokesh\n",
        "- Supriya Singh\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# OPENAI SETUP\n",
        "\n",
        "API_KEY = \"API_KEY\"\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "# Model selection dropdown\n",
        "model_options = {\n",
        "    \"GPT-4o-mini (fast)\": \"gpt-4o-mini\",\n",
        "    \"GPT-4-Turbo (advanced)\": \"gpt-4-turbo\",\n",
        "    \"GPT-3.5-Turbo (classic)\": \"gpt-3.5-turbo\"\n",
        "}\n",
        "selected_model = st.sidebar.selectbox(\"ðŸ¤– Choose LLM Model:\", list(model_options.keys()))\n",
        "selected_model_name = model_options[selected_model]\n",
        "\n",
        "# Session state\n",
        "if \"portfolio_df\" not in st.session_state:\n",
        "    st.session_state[\"portfolio_df\"] = None\n",
        "if \"portfolio_fig1\" not in st.session_state:\n",
        "    st.session_state[\"portfolio_fig1\"] = None\n",
        "if \"portfolio_fig2\" not in st.session_state:\n",
        "    st.session_state[\"portfolio_fig2\"] = None\n",
        "\n",
        "\n",
        "# PORTFOLIO ANALYSIS SECTION\n",
        "\n",
        "st.subheader(\"Generate Your Portfolio\")\n",
        "\n",
        "num = st.slider(\"Select number of S&P 500 stocks to analyze\", 10, 500, 50)\n",
        "run = st.button(\"Generate Portfolio\")\n",
        "\n",
        "if run:\n",
        "    st.info(f\"â³ Fetching market data and sentiment using {selected_model}â€¦\")\n",
        "    tickers = get_sp500_tickers()[:num]\n",
        "    # Pass selected model to backend\n",
        "    st.session_state[\"portfolio_df\"], st.session_state[\"portfolio_fig1\"], st.session_state[\"portfolio_fig2\"] = generate_portfolio(tickers, client)\n",
        "    st.success(f\"Portfolio generated successfully for {num} tickers!\")\n",
        "\n",
        "# Show visualizations and data table\n",
        "if st.session_state[\"portfolio_df\"] is not None:\n",
        "    st.plotly_chart(st.session_state[\"portfolio_fig1\"], use_container_width=True)\n",
        "    st.plotly_chart(st.session_state[\"portfolio_fig2\"], use_container_width=True)\n",
        "\n",
        "    total_tickers = len(st.session_state[\"portfolio_df\"])\n",
        "    default_view = 25 if total_tickers >= 25 else total_tickers\n",
        "    display_n = st.number_input(\"View Top N Tickers in Table\", min_value=1, max_value=total_tickers, value=default_view, step=5)\n",
        "    st.dataframe(st.session_state[\"portfolio_df\"][[\"Ticker\", \"Sharpe\", \"Sentiment\", \"Score\", \"Weight\"]].head(int(display_n)))\n",
        "\n",
        "\n",
        "# COPILOT CHAT SECTION\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"ðŸ¤– Copilot Chat â€” Ask About Your Portfolio\")\n",
        "\n",
        "query = st.text_input(\"Ask RebalanceAI (e.g. 'Top 5 bullish stocks' or 'Compare NVDA vs TSLA')\")\n",
        "\n",
        "if query:\n",
        "    st.info(f\"Analyzing with {selected_model}â€¦\")\n",
        "    df = st.session_state[\"portfolio_df\"]\n",
        "    if df is None:\n",
        "        context = \"No portfolio data yet. Please run the analysis above first.\"\n",
        "    else:\n",
        "        context = df.to_string(index=False)\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a financial copilot analyzing the userâ€™s portfolio. \"\n",
        "        \"Base your answer on the data below.\\n\\n\"\n",
        "        f\"{context}\\n\\nUser Query: {query}\"\n",
        "    )\n",
        "\n",
        "    r = client.chat.completions.create(\n",
        "        model=selected_model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3,\n",
        "    )\n",
        "\n",
        "    st.markdown(\"**ðŸ§­ Copilot Response:**\")\n",
        "    st.write(r.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzVrSex7Pf1R",
        "outputId": "97588c13-e384-4d65-aac4-0000bf485f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install & import\n",
        "!pip install streamlit pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "import threading, time, os\n",
        "\n",
        "# Kill any old tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start Streamlit server in a thread\n",
        "def start_streamlit():\n",
        "    os.system(\"python -m streamlit run app.py --server.port 8501\")\n",
        "\n",
        "t = threading.Thread(target=start_streamlit, daemon=True)\n",
        "t.start()\n",
        "\n",
        "# Wait for Streamlit to boot up\n",
        "time.sleep(8)\n",
        "\n",
        "# Create public tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸŒ  Your public app URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GyW-Q-V9nkn",
        "outputId": "38e40811-e6e7-41ea-9275-83e443e280f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ  Your public app URL: NgrokTunnel: \"https://semicylindrical-korbin-unperilously.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}